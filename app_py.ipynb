{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUo8Wh+3OQs2gd4sVS4m8b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nug1209/Cek_Hoaks/blob/main/app_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCMh6kpJERXD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# !pip install transformers\n",
        "# !pip install streamlit\n",
        "\n",
        "import re\n",
        "import string\n",
        "from torch import clamp\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import streamlit as st"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenSimilarity:\n",
        "\n",
        "  def load_pretrained(self, from_pretrained:str='indobenchmark/indobert-base-p1'):\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(from_pretrained)\n",
        "    self.model = AutoModel.from_pretrained(from_pretrained)\n",
        "  \n",
        "  def __cleaning(self, text:str):\n",
        "    text = text.translate(str.maketrans('', ''))\n",
        "\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    text = re.sub(r'/s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "  def __process(self, first_token:str, second_token:str):\n",
        "\n",
        "    inputs = self.tokenizer([first_token, second_token], max_length=self.max_length, truncation=self.truncation, padding=self.padding, return_tensors='pt')\n",
        "    \n",
        "    attention = inputs.attention_mask\n",
        "    \n",
        "    outputs = self.model(**inputs)\n",
        "\n",
        "    embeddings = outputs[0]\n",
        "\n",
        "    embeddings = outputs.last_hidden_state\n",
        "\n",
        "    mask = attention.unsqueeze(-1).expand(embeddings.shape).float()\n",
        "\n",
        "    masked_embeddings = embeddings * mask\n",
        "\n",
        "    summed = masked_embeddings.sum(1)\n",
        "\n",
        "    counts = clamp(mask.sum(1), min = 1e-9)\n",
        "\n",
        "    mean_pooled = summed / counts\n",
        "\n",
        "    return mean_pooled.detach().numpy()\n",
        "\n",
        "  def predict(self, first_token:str, second_token:str, return_as_embeddings:bool=False, max_length:int=16, truncation:bool=True, padding:str='max_length'):\n",
        "    \n",
        "    self.max_length = max_length\n",
        "    self.truncation = truncation\n",
        "    self.padding = padding\n",
        "\n",
        "    first_token = self.__cleaning(first_token)\n",
        "\n",
        "    second_token = self.__cleaning(second_token)\n",
        "\n",
        "    mean_pooled_arr = self.__process(first_token, second_token)\n",
        "\n",
        "    if return_as_embeddings:\n",
        "      return mean_pooled_arr\n",
        "    \n",
        "    similarity = cosine_similarity([mean_pooled_arr[0]], [mean_pooled_arr[1]])\n",
        "\n",
        "    return similarity"
      ],
      "metadata": {
        "id": "mXk_QfnCP0zL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st.title('CEK HOAKS')\n",
        "\n",
        "model = TokenSimilarity()\n",
        "model.load_pretrained('indobenchmark/indobert-base-p2')\n",
        "\n",
        "df = pd.read_excel('hoax.xlsx')"
      ],
      "metadata": {
        "id": "UUXEPqYYE3O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def clear_submit():\n",
        "#   st.session_state['submit'] = False"
      ],
      "metadata": {
        "id": "yfQLP_j4u8cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_check = st.text_area('Teks yang mau dicek...')\n",
        "\n",
        "\n",
        "if to_check:\n",
        "  \n",
        "  for i in np.arange(len(df['text'])):\n",
        "  result = model.predict(to_check, df['text'][i])\n",
        "  st.json(result)\n",
        "\n"
      ],
      "metadata": {
        "id": "w_Txq-BWD7L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to_check = st.text_area('Tulis teks yang diduga hoaks', on_change=clear_submit)\n",
        "\n",
        "# for i in np.arange(len(df['text'])):\n",
        "#   result = model.predict(to_check, df['text'][i])\n",
        "#   print('Comparing with hoax', i)\n",
        "#   print('Similarity score', result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsuBE_-fV0Iz",
        "outputId": "17a60ffd-6ffd-4e44-c537-54895d3cde1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing with hoax 0\n",
            "Similarity score [[0.32880262]]\n",
            "Comparing with hoax 1\n",
            "Similarity score [[0.67949766]]\n",
            "Comparing with hoax 2\n",
            "Similarity score [[0.47883797]]\n",
            "Comparing with hoax 3\n",
            "Similarity score [[0.3673395]]\n",
            "Comparing with hoax 4\n",
            "Similarity score [[0.44255802]]\n",
            "Comparing with hoax 5\n",
            "Similarity score [[0.4178806]]\n",
            "Comparing with hoax 6\n",
            "Similarity score [[0.38824967]]\n"
          ]
        }
      ]
    }
  ]
}